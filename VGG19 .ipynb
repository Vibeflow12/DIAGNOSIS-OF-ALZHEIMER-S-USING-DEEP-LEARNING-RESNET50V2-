{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "pip install split_folders"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rcp2B2FKFxS9",
        "outputId": "31aa2262-3a38-4b4a-e815-1f725d1582a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting split_folders\n",
            "  Downloading split_folders-0.5.1-py3-none-any.whl (8.4 kB)\n",
            "Installing collected packages: split_folders\n",
            "Successfully installed split_folders-0.5.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import splitfolders"
      ],
      "metadata": {
        "id": "7lPfV6NFF0Bo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_folder = \"/content/drive/MyDrive/colab nootbook/ressnet/input_dataset\"\n",
        "output = \"/content/drive/MyDrive/colab nootbook/ressnet/processed_data\"\n",
        "splitfolders.ratio(input_folder, output, seed=42, ratio=(.6, .2, .2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BvyZM_4GF0Mc",
        "outputId": "280c7dab-85b6-4315-9ad9-0f824739885b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Copying files: 10300 files [01:32, 111.22 files/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N7zk9QqSCbAh"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.layers import Conv2D,Flatten,Dense,MaxPool2D,BatchNormalization, GlobalAveragePooling2D\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator ,load_img\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
        "from tensorflow.keras.applications.inception_v3 import preprocess_input\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.models import Model\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import scipy\n",
        "\n",
        "\n",
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
        "\n",
        "\n",
        "from tensorflow.keras.applications import VGG19\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, History\n",
        "import pickle\n",
        "import subprocess"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "img_height,img_width=(224,224)\n",
        "batch_size = 70\n",
        "\n",
        "train_data_dir = r\"/content/drive/MyDrive/colab nootbook/ressnet/processed data/train\"\n",
        "valid_data_dir = r\"/content/drive/MyDrive/colab nootbook/ressnet/processed data/val\"\n",
        "test_data_dir = r\"/content/drive/MyDrive/colab nootbook/ressnet/processed data/test\""
      ],
      "metadata": {
        "id": "_RNar9YmCk3P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_datagen = ImageDataGenerator(preprocessing_function=preprocess_input,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    validation_split=0.4)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_data_dir,\n",
        "    target_size=(img_height, img_width),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical',\n",
        "    subset='training')\n",
        "\n",
        "valid_generator = train_datagen.flow_from_directory(\n",
        "    valid_data_dir,\n",
        "    target_size=(img_height, img_width),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical',\n",
        "    subset='validation')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ozgR5WyClaR",
        "outputId": "4ee54a0c-0d1f-420e-9b5e-ff7bfc5fab66"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 3688 images belonging to 4 classes.\n",
            "Found 816 images belonging to 4 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_generator = train_datagen.flow_from_directory(\n",
        "    test_data_dir,\n",
        "    target_size=(224, 224),\n",
        "    class_mode='categorical',\n",
        "    subset='validation'\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qbJLNa7WCrfw",
        "outputId": "7888a147-e4b4-42ca-95d5-d6792c2c4f18"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 816 images belonging to 4 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x,y = test_generator.next()\n",
        "print(x,y.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JwjHnrZACsLF",
        "outputId": "75986c53-582f-4c6e-cec0-af7127ea2e86"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[[[-1.         -1.         -1.        ]\n",
            "   [-1.         -1.         -1.        ]\n",
            "   [-1.         -1.         -1.        ]\n",
            "   ...\n",
            "   [-1.         -1.         -1.        ]\n",
            "   [-1.         -1.         -1.        ]\n",
            "   [-1.         -1.         -1.        ]]\n",
            "\n",
            "  [[-1.         -1.         -1.        ]\n",
            "   [-1.         -1.         -1.        ]\n",
            "   [-1.         -1.         -1.        ]\n",
            "   ...\n",
            "   [-1.         -1.         -1.        ]\n",
            "   [-1.         -1.         -1.        ]\n",
            "   [-1.         -1.         -1.        ]]\n",
            "\n",
            "  [[-1.         -1.         -1.        ]\n",
            "   [-1.         -1.         -1.        ]\n",
            "   [-1.         -1.         -1.        ]\n",
            "   ...\n",
            "   [-1.         -1.         -1.        ]\n",
            "   [-1.         -1.         -1.        ]\n",
            "   [-1.         -1.         -1.        ]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[-1.         -1.         -1.        ]\n",
            "   [-1.         -1.         -1.        ]\n",
            "   [-1.         -1.         -1.        ]\n",
            "   ...\n",
            "   [-1.         -1.         -1.        ]\n",
            "   [-1.         -1.         -1.        ]\n",
            "   [-1.         -1.         -1.        ]]\n",
            "\n",
            "  [[-1.         -1.         -1.        ]\n",
            "   [-1.         -1.         -1.        ]\n",
            "   [-1.         -1.         -1.        ]\n",
            "   ...\n",
            "   [-1.         -1.         -1.        ]\n",
            "   [-1.         -1.         -1.        ]\n",
            "   [-1.         -1.         -1.        ]]\n",
            "\n",
            "  [[-1.         -1.         -1.        ]\n",
            "   [-1.         -1.         -1.        ]\n",
            "   [-1.         -1.         -1.        ]\n",
            "   ...\n",
            "   [-1.         -1.         -1.        ]\n",
            "   [-1.         -1.         -1.        ]\n",
            "   [-1.         -1.         -1.        ]]]\n",
            "\n",
            "\n",
            " [[[-1.         -1.         -1.        ]\n",
            "   [-1.         -1.         -1.        ]\n",
            "   [-1.         -1.         -1.        ]\n",
            "   ...\n",
            "   [-0.99215686 -0.99215686 -0.99215686]\n",
            "   [-0.99215686 -0.99215686 -0.99215686]\n",
            "   [-0.99215686 -0.99215686 -0.99215686]]\n",
            "\n",
            "  [[-1.         -1.         -1.        ]\n",
            "   [-1.         -1.         -1.        ]\n",
            "   [-1.         -1.         -1.        ]\n",
            "   ...\n",
            "   [-0.99215686 -0.99215686 -0.99215686]\n",
            "   [-0.99215686 -0.99215686 -0.99215686]\n",
            "   [-0.99215686 -0.99215686 -0.99215686]]\n",
            "\n",
            "  [[-1.         -1.         -1.        ]\n",
            "   [-1.         -1.         -1.        ]\n",
            "   [-1.         -1.         -1.        ]\n",
            "   ...\n",
            "   [-0.99215686 -0.99215686 -0.99215686]\n",
            "   [-0.99215686 -0.99215686 -0.99215686]\n",
            "   [-0.99215686 -0.99215686 -0.99215686]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[-0.99215686 -0.99215686 -0.99215686]\n",
            "   [-0.99215686 -0.99215686 -0.99215686]\n",
            "   [-0.99215686 -0.99215686 -0.99215686]\n",
            "   ...\n",
            "   [-0.9987139  -0.9987139  -0.9987139 ]\n",
            "   [-0.9989171  -0.9989171  -0.9989171 ]\n",
            "   [-0.9999508  -0.9999508  -0.9999508 ]]\n",
            "\n",
            "  [[-0.99215686 -0.99215686 -0.99215686]\n",
            "   [-0.99215686 -0.99215686 -0.99215686]\n",
            "   [-0.99215686 -0.99215686 -0.99215686]\n",
            "   ...\n",
            "   [-1.         -1.         -1.        ]\n",
            "   [-1.         -1.         -1.        ]\n",
            "   [-1.         -1.         -1.        ]]\n",
            "\n",
            "  [[-0.99215686 -0.99215686 -0.99215686]\n",
            "   [-0.99215686 -0.99215686 -0.99215686]\n",
            "   [-0.99215686 -0.99215686 -0.99215686]\n",
            "   ...\n",
            "   [-1.         -1.         -1.        ]\n",
            "   [-1.         -1.         -1.        ]\n",
            "   [-1.         -1.         -1.        ]]]\n",
            "\n",
            "\n",
            " [[[-0.99949896 -0.99949896 -0.99949896]\n",
            "   [-0.9924311  -0.9924311  -0.9924311 ]\n",
            "   [-0.99215686 -0.99215686 -0.99215686]\n",
            "   ...\n",
            "   [-1.         -1.         -1.        ]\n",
            "   [-1.         -1.         -1.        ]\n",
            "   [-1.         -1.         -1.        ]]\n",
            "\n",
            "  [[-0.9998497  -0.9998497  -0.9998497 ]\n",
            "   [-0.9977166  -0.9977166  -0.9977166 ]\n",
            "   [-0.9976329  -0.9976329  -0.9976329 ]\n",
            "   ...\n",
            "   [-1.         -1.         -1.        ]\n",
            "   [-1.         -1.         -1.        ]\n",
            "   [-1.         -1.         -1.        ]]\n",
            "\n",
            "  [[-1.         -1.         -1.        ]\n",
            "   [-1.         -1.         -1.        ]\n",
            "   [-1.         -1.         -1.        ]\n",
            "   ...\n",
            "   [-1.         -1.         -1.        ]\n",
            "   [-1.         -1.         -1.        ]\n",
            "   [-1.         -1.         -1.        ]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[-1.         -1.         -1.        ]\n",
            "   [-1.         -1.         -1.        ]\n",
            "   [-1.         -1.         -1.        ]\n",
            "   ...\n",
            "   [-1.         -1.         -1.        ]\n",
            "   [-1.         -1.         -1.        ]\n",
            "   [-1.         -1.         -1.        ]]\n",
            "\n",
            "  [[-1.         -1.         -1.        ]\n",
            "   [-1.         -1.         -1.        ]\n",
            "   [-1.         -1.         -1.        ]\n",
            "   ...\n",
            "   [-1.         -1.         -1.        ]\n",
            "   [-1.         -1.         -1.        ]\n",
            "   [-1.         -1.         -1.        ]]\n",
            "\n",
            "  [[-1.         -1.         -1.        ]\n",
            "   [-1.         -1.         -1.        ]\n",
            "   [-1.         -1.         -1.        ]\n",
            "   ...\n",
            "   [-1.         -1.         -1.        ]\n",
            "   [-1.         -1.         -1.        ]\n",
            "   [-1.         -1.         -1.        ]]]\n",
            "\n",
            "\n",
            " ...\n",
            "\n",
            "\n",
            " [[[-1.         -1.         -1.        ]\n",
            "   [-1.         -1.         -1.        ]\n",
            "   [-1.         -1.         -1.        ]\n",
            "   ...\n",
            "   [-1.         -1.         -1.        ]\n",
            "   [-1.         -1.         -1.        ]\n",
            "   [-1.         -1.         -1.        ]]\n",
            "\n",
            "  [[-1.         -1.         -1.        ]\n",
            "   [-1.         -1.         -1.        ]\n",
            "   [-1.         -1.         -1.        ]\n",
            "   ...\n",
            "   [-1.         -1.         -1.        ]\n",
            "   [-1.         -1.         -1.        ]\n",
            "   [-1.         -1.         -1.        ]]\n",
            "\n",
            "  [[-1.         -1.         -1.        ]\n",
            "   [-1.         -1.         -1.        ]\n",
            "   [-1.         -1.         -1.        ]\n",
            "   ...\n",
            "   [-1.         -1.         -1.        ]\n",
            "   [-1.         -1.         -1.        ]\n",
            "   [-1.         -1.         -1.        ]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[-1.         -1.         -1.        ]\n",
            "   [-1.         -1.         -1.        ]\n",
            "   [-1.         -1.         -1.        ]\n",
            "   ...\n",
            "   [-1.         -1.         -1.        ]\n",
            "   [-1.         -1.         -1.        ]\n",
            "   [-1.         -1.         -1.        ]]\n",
            "\n",
            "  [[-1.         -1.         -1.        ]\n",
            "   [-1.         -1.         -1.        ]\n",
            "   [-1.         -1.         -1.        ]\n",
            "   ...\n",
            "   [-1.         -1.         -1.        ]\n",
            "   [-1.         -1.         -1.        ]\n",
            "   [-1.         -1.         -1.        ]]\n",
            "\n",
            "  [[-1.         -1.         -1.        ]\n",
            "   [-1.         -1.         -1.        ]\n",
            "   [-1.         -1.         -1.        ]\n",
            "   ...\n",
            "   [-1.         -1.         -1.        ]\n",
            "   [-1.         -1.         -1.        ]\n",
            "   [-1.         -1.         -1.        ]]]\n",
            "\n",
            "\n",
            " [[[-1.         -1.         -1.        ]\n",
            "   [-1.         -1.         -1.        ]\n",
            "   [-1.         -1.         -1.        ]\n",
            "   ...\n",
            "   [-1.         -1.         -1.        ]\n",
            "   [-1.         -1.         -1.        ]\n",
            "   [-1.         -1.         -1.        ]]\n",
            "\n",
            "  [[-1.         -1.         -1.        ]\n",
            "   [-1.         -1.         -1.        ]\n",
            "   [-1.         -1.         -1.        ]\n",
            "   ...\n",
            "   [-1.         -1.         -1.        ]\n",
            "   [-1.         -1.         -1.        ]\n",
            "   [-1.         -1.         -1.        ]]\n",
            "\n",
            "  [[-1.         -1.         -1.        ]\n",
            "   [-1.         -1.         -1.        ]\n",
            "   [-1.         -1.         -1.        ]\n",
            "   ...\n",
            "   [-1.         -1.         -1.        ]\n",
            "   [-1.         -1.         -1.        ]\n",
            "   [-1.         -1.         -1.        ]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[-1.         -1.         -1.        ]\n",
            "   [-1.         -1.         -1.        ]\n",
            "   [-1.         -1.         -1.        ]\n",
            "   ...\n",
            "   [-1.         -1.         -1.        ]\n",
            "   [-1.         -1.         -1.        ]\n",
            "   [-1.         -1.         -1.        ]]\n",
            "\n",
            "  [[-1.         -1.         -1.        ]\n",
            "   [-1.         -1.         -1.        ]\n",
            "   [-1.         -1.         -1.        ]\n",
            "   ...\n",
            "   [-1.         -1.         -1.        ]\n",
            "   [-1.         -1.         -1.        ]\n",
            "   [-1.         -1.         -1.        ]]\n",
            "\n",
            "  [[-1.         -1.         -1.        ]\n",
            "   [-1.         -1.         -1.        ]\n",
            "   [-1.         -1.         -1.        ]\n",
            "   ...\n",
            "   [-1.         -1.         -1.        ]\n",
            "   [-1.         -1.         -1.        ]\n",
            "   [-1.         -1.         -1.        ]]]\n",
            "\n",
            "\n",
            " [[[-1.         -1.         -1.        ]\n",
            "   [-1.         -1.         -1.        ]\n",
            "   [-1.         -1.         -1.        ]\n",
            "   ...\n",
            "   [-1.         -1.         -1.        ]\n",
            "   [-1.         -1.         -1.        ]\n",
            "   [-1.         -1.         -1.        ]]\n",
            "\n",
            "  [[-1.         -1.         -1.        ]\n",
            "   [-1.         -1.         -1.        ]\n",
            "   [-1.         -1.         -1.        ]\n",
            "   ...\n",
            "   [-1.         -1.         -1.        ]\n",
            "   [-1.         -1.         -1.        ]\n",
            "   [-1.         -1.         -1.        ]]\n",
            "\n",
            "  [[-1.         -1.         -1.        ]\n",
            "   [-1.         -1.         -1.        ]\n",
            "   [-1.         -1.         -1.        ]\n",
            "   ...\n",
            "   [-1.         -1.         -1.        ]\n",
            "   [-1.         -1.         -1.        ]\n",
            "   [-1.         -1.         -1.        ]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[-1.         -1.         -1.        ]\n",
            "   [-1.         -1.         -1.        ]\n",
            "   [-1.         -1.         -1.        ]\n",
            "   ...\n",
            "   [-1.         -1.         -1.        ]\n",
            "   [-1.         -1.         -1.        ]\n",
            "   [-1.         -1.         -1.        ]]\n",
            "\n",
            "  [[-1.         -1.         -1.        ]\n",
            "   [-1.         -1.         -1.        ]\n",
            "   [-1.         -1.         -1.        ]\n",
            "   ...\n",
            "   [-1.         -1.         -1.        ]\n",
            "   [-1.         -1.         -1.        ]\n",
            "   [-1.         -1.         -1.        ]]\n",
            "\n",
            "  [[-1.         -1.         -1.        ]\n",
            "   [-1.         -1.         -1.        ]\n",
            "   [-1.         -1.         -1.        ]\n",
            "   ...\n",
            "   [-1.         -1.         -1.        ]\n",
            "   [-1.         -1.         -1.        ]\n",
            "   [-1.         -1.         -1.        ]]]] (32, 4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "base_model = VGG19(include_top=False, weights='imagenet')\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dense(1024, activation='relu')(x)\n",
        "predictions = Dense(train_generator.num_classes, activation='softmax')(x)\n",
        "model = Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "model_checkpoint_loss = ModelCheckpoint('VGG19_model_loss.h5', save_best_only=True, monitor='val_loss', mode='min', verbose=1, save_weights_only=False)\n",
        "model_checkpoint_accuracy = ModelCheckpoint('VGG19_model_accuracy.h5', save_best_only=True, monitor='val_accuracy', mode='max', verbose=1, save_weights_only=False)\n",
        "\n",
        "history_callback = History()\n",
        "\n",
        "#model.fit(train_generator, epochs=100, verbose = 2 )\n",
        "\n",
        "history = model.fit(train_generator, epochs=100, verbose=2, validation_data=valid_generator, callbacks=[model_checkpoint_loss, model_checkpoint_accuracy, history_callback])\n",
        "\n",
        "with open(' VGG19_training_history.pkl', 'wb') as file:\n",
        "    pickle.dump(history.history, file)\n",
        "\n",
        "\n",
        "training_accuracy = history.history['accuracy']\n",
        "validation_accuracy = history.history['val_accuracy']\n",
        "training_loss = history.history['loss']\n",
        "validation_loss = history.history['val_loss']\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bXavALAJCv7T",
        "outputId": "88af363d-0d2a-49d2-8de9-052e892042bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg19/vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "80134624/80134624 [==============================] - 0s 0us/step\n",
            "Epoch 1/100\n",
            "\n",
            "Epoch 1: val_loss improved from inf to 1.29957, saving model to VGG19_model_loss.h5\n",
            "\n",
            "Epoch 1: val_accuracy improved from -inf to 0.27941, saving model to VGG19_model_accuracy.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "53/53 - 1765s - loss: 1.2630 - accuracy: 0.4170 - val_loss: 1.2996 - val_accuracy: 0.2794 - 1765s/epoch - 33s/step\n",
            "Epoch 2/100\n",
            "\n",
            "Epoch 2: val_loss improved from 1.29957 to 1.12441, saving model to VGG19_model_loss.h5\n",
            "\n",
            "Epoch 2: val_accuracy improved from 0.27941 to 0.45956, saving model to VGG19_model_accuracy.h5\n",
            "53/53 - 72s - loss: 1.0002 - accuracy: 0.5979 - val_loss: 1.1244 - val_accuracy: 0.4596 - 72s/epoch - 1s/step\n",
            "Epoch 3/100\n",
            "\n",
            "Epoch 3: val_loss improved from 1.12441 to 1.00600, saving model to VGG19_model_loss.h5\n",
            "\n",
            "Epoch 3: val_accuracy improved from 0.45956 to 0.56618, saving model to VGG19_model_accuracy.h5\n",
            "53/53 - 71s - loss: 0.8653 - accuracy: 0.6521 - val_loss: 1.0060 - val_accuracy: 0.5662 - 71s/epoch - 1s/step\n",
            "Epoch 4/100\n",
            "\n",
            "Epoch 4: val_loss did not improve from 1.00600\n",
            "\n",
            "Epoch 4: val_accuracy did not improve from 0.56618\n",
            "53/53 - 70s - loss: 0.7965 - accuracy: 0.6665 - val_loss: 1.0408 - val_accuracy: 0.5404 - 70s/epoch - 1s/step\n",
            "Epoch 5/100\n",
            "\n",
            "Epoch 5: val_loss improved from 1.00600 to 0.94692, saving model to VGG19_model_loss.h5\n",
            "\n",
            "Epoch 5: val_accuracy improved from 0.56618 to 0.63480, saving model to VGG19_model_accuracy.h5\n",
            "53/53 - 72s - loss: 0.7363 - accuracy: 0.6898 - val_loss: 0.9469 - val_accuracy: 0.6348 - 72s/epoch - 1s/step\n",
            "Epoch 6/100\n",
            "\n",
            "Epoch 6: val_loss improved from 0.94692 to 0.91834, saving model to VGG19_model_loss.h5\n",
            "\n",
            "Epoch 6: val_accuracy did not improve from 0.63480\n",
            "53/53 - 72s - loss: 0.7008 - accuracy: 0.6952 - val_loss: 0.9183 - val_accuracy: 0.5686 - 72s/epoch - 1s/step\n",
            "Epoch 7/100\n",
            "\n",
            "Epoch 7: val_loss did not improve from 0.91834\n",
            "\n",
            "Epoch 7: val_accuracy did not improve from 0.63480\n",
            "53/53 - 72s - loss: 0.6730 - accuracy: 0.7202 - val_loss: 1.0378 - val_accuracy: 0.5539 - 72s/epoch - 1s/step\n",
            "Epoch 8/100\n",
            "\n",
            "Epoch 8: val_loss improved from 0.91834 to 0.89990, saving model to VGG19_model_loss.h5\n",
            "\n",
            "Epoch 8: val_accuracy did not improve from 0.63480\n",
            "53/53 - 78s - loss: 0.6714 - accuracy: 0.7028 - val_loss: 0.8999 - val_accuracy: 0.5993 - 78s/epoch - 1s/step\n",
            "Epoch 9/100\n",
            "\n",
            "Epoch 9: val_loss did not improve from 0.89990\n",
            "\n",
            "Epoch 9: val_accuracy did not improve from 0.63480\n",
            "53/53 - 71s - loss: 0.6270 - accuracy: 0.7264 - val_loss: 0.9016 - val_accuracy: 0.5441 - 71s/epoch - 1s/step\n",
            "Epoch 10/100\n",
            "\n",
            "Epoch 10: val_loss did not improve from 0.89990\n",
            "\n",
            "Epoch 10: val_accuracy did not improve from 0.63480\n",
            "53/53 - 71s - loss: 0.6054 - accuracy: 0.7465 - val_loss: 0.9034 - val_accuracy: 0.6275 - 71s/epoch - 1s/step\n",
            "Epoch 11/100\n",
            "\n",
            "Epoch 11: val_loss did not improve from 0.89990\n",
            "\n",
            "Epoch 11: val_accuracy did not improve from 0.63480\n",
            "53/53 - 71s - loss: 0.5962 - accuracy: 0.7440 - val_loss: 0.9584 - val_accuracy: 0.5882 - 71s/epoch - 1s/step\n",
            "Epoch 12/100\n",
            "\n",
            "Epoch 12: val_loss improved from 0.89990 to 0.87018, saving model to VGG19_model_loss.h5\n",
            "\n",
            "Epoch 12: val_accuracy did not improve from 0.63480\n",
            "53/53 - 79s - loss: 0.5736 - accuracy: 0.7636 - val_loss: 0.8702 - val_accuracy: 0.6005 - 79s/epoch - 1s/step\n",
            "Epoch 13/100\n",
            "\n",
            "Epoch 13: val_loss did not improve from 0.87018\n",
            "\n",
            "Epoch 13: val_accuracy did not improve from 0.63480\n",
            "53/53 - 71s - loss: 0.5654 - accuracy: 0.7600 - val_loss: 0.9010 - val_accuracy: 0.6250 - 71s/epoch - 1s/step\n",
            "Epoch 14/100\n",
            "\n",
            "Epoch 14: val_loss did not improve from 0.87018\n",
            "\n",
            "Epoch 14: val_accuracy did not improve from 0.63480\n",
            "53/53 - 71s - loss: 0.5821 - accuracy: 0.7424 - val_loss: 0.9014 - val_accuracy: 0.5980 - 71s/epoch - 1s/step\n",
            "Epoch 15/100\n",
            "\n",
            "Epoch 15: val_loss did not improve from 0.87018\n",
            "\n",
            "Epoch 15: val_accuracy did not improve from 0.63480\n",
            "53/53 - 71s - loss: 0.5399 - accuracy: 0.7733 - val_loss: 0.9060 - val_accuracy: 0.6127 - 71s/epoch - 1s/step\n",
            "Epoch 16/100\n",
            "\n",
            "Epoch 16: val_loss improved from 0.87018 to 0.82927, saving model to VGG19_model_loss.h5\n",
            "\n",
            "Epoch 16: val_accuracy did not improve from 0.63480\n",
            "53/53 - 80s - loss: 0.5462 - accuracy: 0.7636 - val_loss: 0.8293 - val_accuracy: 0.6299 - 80s/epoch - 2s/step\n",
            "Epoch 17/100\n",
            "\n",
            "Epoch 17: val_loss did not improve from 0.82927\n",
            "\n",
            "Epoch 17: val_accuracy did not improve from 0.63480\n",
            "53/53 - 71s - loss: 0.5234 - accuracy: 0.7817 - val_loss: 0.8989 - val_accuracy: 0.6152 - 71s/epoch - 1s/step\n",
            "Epoch 18/100\n",
            "\n",
            "Epoch 18: val_loss did not improve from 0.82927\n",
            "\n",
            "Epoch 18: val_accuracy did not improve from 0.63480\n",
            "53/53 - 71s - loss: 0.5187 - accuracy: 0.7801 - val_loss: 0.9485 - val_accuracy: 0.6140 - 71s/epoch - 1s/step\n",
            "Epoch 19/100\n",
            "\n",
            "Epoch 19: val_loss did not improve from 0.82927\n",
            "\n",
            "Epoch 19: val_accuracy improved from 0.63480 to 0.64583, saving model to VGG19_model_accuracy.h5\n",
            "53/53 - 72s - loss: 0.5166 - accuracy: 0.7831 - val_loss: 0.8675 - val_accuracy: 0.6458 - 72s/epoch - 1s/step\n",
            "Epoch 20/100\n",
            "\n",
            "Epoch 20: val_loss did not improve from 0.82927\n",
            "\n",
            "Epoch 20: val_accuracy did not improve from 0.64583\n",
            "53/53 - 71s - loss: 0.5238 - accuracy: 0.7752 - val_loss: 0.9316 - val_accuracy: 0.6189 - 71s/epoch - 1s/step\n",
            "Epoch 21/100\n",
            "\n",
            "Epoch 21: val_loss did not improve from 0.82927\n",
            "\n",
            "Epoch 21: val_accuracy did not improve from 0.64583\n",
            "53/53 - 70s - loss: 0.5255 - accuracy: 0.7782 - val_loss: 0.9323 - val_accuracy: 0.6176 - 70s/epoch - 1s/step\n",
            "Epoch 22/100\n",
            "\n",
            "Epoch 22: val_loss did not improve from 0.82927\n",
            "\n",
            "Epoch 22: val_accuracy did not improve from 0.64583\n",
            "53/53 - 70s - loss: 0.5169 - accuracy: 0.7812 - val_loss: 0.9011 - val_accuracy: 0.6385 - 70s/epoch - 1s/step\n",
            "Epoch 23/100\n",
            "\n",
            "Epoch 23: val_loss did not improve from 0.82927\n",
            "\n",
            "Epoch 23: val_accuracy did not improve from 0.64583\n",
            "53/53 - 70s - loss: 0.5230 - accuracy: 0.7820 - val_loss: 0.9381 - val_accuracy: 0.6201 - 70s/epoch - 1s/step\n",
            "Epoch 24/100\n",
            "\n",
            "Epoch 24: val_loss did not improve from 0.82927\n",
            "\n",
            "Epoch 24: val_accuracy improved from 0.64583 to 0.65074, saving model to VGG19_model_accuracy.h5\n",
            "53/53 - 70s - loss: 0.4849 - accuracy: 0.7947 - val_loss: 0.8696 - val_accuracy: 0.6507 - 70s/epoch - 1s/step\n",
            "Epoch 25/100\n",
            "\n",
            "Epoch 25: val_loss did not improve from 0.82927\n",
            "\n",
            "Epoch 25: val_accuracy did not improve from 0.65074\n",
            "53/53 - 68s - loss: 0.4881 - accuracy: 0.7918 - val_loss: 1.0156 - val_accuracy: 0.6262 - 68s/epoch - 1s/step\n",
            "Epoch 26/100\n",
            "\n",
            "Epoch 26: val_loss did not improve from 0.82927\n",
            "\n",
            "Epoch 26: val_accuracy did not improve from 0.65074\n",
            "53/53 - 70s - loss: 0.4764 - accuracy: 0.8007 - val_loss: 0.8630 - val_accuracy: 0.6189 - 70s/epoch - 1s/step\n",
            "Epoch 27/100\n",
            "\n",
            "Epoch 27: val_loss did not improve from 0.82927\n",
            "\n",
            "Epoch 27: val_accuracy did not improve from 0.65074\n",
            "53/53 - 69s - loss: 0.4982 - accuracy: 0.7915 - val_loss: 0.8686 - val_accuracy: 0.6446 - 69s/epoch - 1s/step\n",
            "Epoch 28/100\n",
            "\n",
            "Epoch 28: val_loss did not improve from 0.82927\n",
            "\n",
            "Epoch 28: val_accuracy did not improve from 0.65074\n",
            "53/53 - 79s - loss: 0.4809 - accuracy: 0.7999 - val_loss: 0.8976 - val_accuracy: 0.6422 - 79s/epoch - 1s/step\n",
            "Epoch 29/100\n",
            "\n",
            "Epoch 29: val_loss did not improve from 0.82927\n",
            "\n",
            "Epoch 29: val_accuracy improved from 0.65074 to 0.65809, saving model to VGG19_model_accuracy.h5\n",
            "53/53 - 70s - loss: 0.4591 - accuracy: 0.8034 - val_loss: 0.9128 - val_accuracy: 0.6581 - 70s/epoch - 1s/step\n",
            "Epoch 30/100\n",
            "\n",
            "Epoch 30: val_loss did not improve from 0.82927\n",
            "\n",
            "Epoch 30: val_accuracy did not improve from 0.65809\n",
            "53/53 - 70s - loss: 0.4668 - accuracy: 0.8034 - val_loss: 0.9397 - val_accuracy: 0.6287 - 70s/epoch - 1s/step\n",
            "Epoch 31/100\n",
            "\n",
            "Epoch 31: val_loss did not improve from 0.82927\n",
            "\n",
            "Epoch 31: val_accuracy did not improve from 0.65809\n",
            "53/53 - 70s - loss: 0.4716 - accuracy: 0.8026 - val_loss: 0.9711 - val_accuracy: 0.6581 - 70s/epoch - 1s/step\n",
            "Epoch 32/100\n",
            "\n",
            "Epoch 32: val_loss did not improve from 0.82927\n",
            "\n",
            "Epoch 32: val_accuracy did not improve from 0.65809\n",
            "53/53 - 70s - loss: 0.4678 - accuracy: 0.8004 - val_loss: 1.0644 - val_accuracy: 0.6225 - 70s/epoch - 1s/step\n",
            "Epoch 33/100\n",
            "\n",
            "Epoch 33: val_loss did not improve from 0.82927\n",
            "\n",
            "Epoch 33: val_accuracy improved from 0.65809 to 0.66422, saving model to VGG19_model_accuracy.h5\n",
            "53/53 - 71s - loss: 0.4441 - accuracy: 0.8105 - val_loss: 0.8805 - val_accuracy: 0.6642 - 71s/epoch - 1s/step\n",
            "Epoch 34/100\n",
            "\n",
            "Epoch 34: val_loss did not improve from 0.82927\n",
            "\n",
            "Epoch 34: val_accuracy did not improve from 0.66422\n",
            "53/53 - 70s - loss: 0.4488 - accuracy: 0.8097 - val_loss: 0.9682 - val_accuracy: 0.6373 - 70s/epoch - 1s/step\n",
            "Epoch 35/100\n",
            "\n",
            "Epoch 35: val_loss did not improve from 0.82927\n",
            "\n",
            "Epoch 35: val_accuracy did not improve from 0.66422\n",
            "53/53 - 71s - loss: 0.4229 - accuracy: 0.8221 - val_loss: 0.9637 - val_accuracy: 0.6127 - 71s/epoch - 1s/step\n",
            "Epoch 36/100\n",
            "\n",
            "Epoch 36: val_loss did not improve from 0.82927\n",
            "\n",
            "Epoch 36: val_accuracy improved from 0.66422 to 0.66667, saving model to VGG19_model_accuracy.h5\n",
            "53/53 - 72s - loss: 0.4335 - accuracy: 0.8200 - val_loss: 0.8918 - val_accuracy: 0.6667 - 72s/epoch - 1s/step\n",
            "Epoch 37/100\n",
            "\n",
            "Epoch 37: val_loss did not improve from 0.82927\n",
            "\n",
            "Epoch 37: val_accuracy did not improve from 0.66667\n",
            "53/53 - 71s - loss: 0.4202 - accuracy: 0.8240 - val_loss: 0.9107 - val_accuracy: 0.6471 - 71s/epoch - 1s/step\n",
            "Epoch 38/100\n",
            "\n",
            "Epoch 38: val_loss did not improve from 0.82927\n",
            "\n",
            "Epoch 38: val_accuracy did not improve from 0.66667\n",
            "53/53 - 71s - loss: 0.4360 - accuracy: 0.8164 - val_loss: 1.0730 - val_accuracy: 0.6115 - 71s/epoch - 1s/step\n",
            "Epoch 39/100\n",
            "\n",
            "Epoch 39: val_loss did not improve from 0.82927\n",
            "\n",
            "Epoch 39: val_accuracy did not improve from 0.66667\n",
            "53/53 - 70s - loss: 0.4320 - accuracy: 0.8183 - val_loss: 0.9583 - val_accuracy: 0.6373 - 70s/epoch - 1s/step\n",
            "Epoch 40/100\n",
            "\n",
            "Epoch 40: val_loss did not improve from 0.82927\n",
            "\n",
            "Epoch 40: val_accuracy did not improve from 0.66667\n",
            "53/53 - 72s - loss: 0.4147 - accuracy: 0.8273 - val_loss: 1.0725 - val_accuracy: 0.6275 - 72s/epoch - 1s/step\n",
            "Epoch 41/100\n",
            "\n",
            "Epoch 41: val_loss did not improve from 0.82927\n",
            "\n",
            "Epoch 41: val_accuracy improved from 0.66667 to 0.68382, saving model to VGG19_model_accuracy.h5\n",
            "53/53 - 71s - loss: 0.4407 - accuracy: 0.8143 - val_loss: 0.8837 - val_accuracy: 0.6838 - 71s/epoch - 1s/step\n",
            "Epoch 42/100\n",
            "\n",
            "Epoch 42: val_loss did not improve from 0.82927\n",
            "\n",
            "Epoch 42: val_accuracy did not improve from 0.68382\n",
            "53/53 - 72s - loss: 0.4392 - accuracy: 0.8191 - val_loss: 0.9429 - val_accuracy: 0.6201 - 72s/epoch - 1s/step\n",
            "Epoch 43/100\n",
            "\n",
            "Epoch 43: val_loss did not improve from 0.82927\n",
            "\n",
            "Epoch 43: val_accuracy did not improve from 0.68382\n",
            "53/53 - 72s - loss: 0.4135 - accuracy: 0.8265 - val_loss: 1.0335 - val_accuracy: 0.6569 - 72s/epoch - 1s/step\n",
            "Epoch 44/100\n",
            "\n",
            "Epoch 44: val_loss did not improve from 0.82927\n",
            "\n",
            "Epoch 44: val_accuracy did not improve from 0.68382\n",
            "53/53 - 72s - loss: 0.4052 - accuracy: 0.8316 - val_loss: 0.8833 - val_accuracy: 0.6654 - 72s/epoch - 1s/step\n",
            "Epoch 45/100\n",
            "\n",
            "Epoch 45: val_loss did not improve from 0.82927\n",
            "\n",
            "Epoch 45: val_accuracy did not improve from 0.68382\n",
            "53/53 - 69s - loss: 0.4119 - accuracy: 0.8313 - val_loss: 0.9221 - val_accuracy: 0.6556 - 69s/epoch - 1s/step\n",
            "Epoch 46/100\n",
            "\n",
            "Epoch 46: val_loss did not improve from 0.82927\n",
            "\n",
            "Epoch 46: val_accuracy did not improve from 0.68382\n",
            "53/53 - 70s - loss: 0.4069 - accuracy: 0.8351 - val_loss: 1.0554 - val_accuracy: 0.6385 - 70s/epoch - 1s/step\n",
            "Epoch 47/100\n",
            "\n",
            "Epoch 47: val_loss did not improve from 0.82927\n",
            "\n",
            "Epoch 47: val_accuracy did not improve from 0.68382\n",
            "53/53 - 70s - loss: 0.4084 - accuracy: 0.8278 - val_loss: 1.0069 - val_accuracy: 0.6311 - 70s/epoch - 1s/step\n",
            "Epoch 48/100\n",
            "\n",
            "Epoch 48: val_loss did not improve from 0.82927\n",
            "\n",
            "Epoch 48: val_accuracy did not improve from 0.68382\n",
            "53/53 - 70s - loss: 0.4171 - accuracy: 0.8243 - val_loss: 1.0260 - val_accuracy: 0.6409 - 70s/epoch - 1s/step\n",
            "Epoch 49/100\n",
            "\n",
            "Epoch 49: val_loss did not improve from 0.82927\n",
            "\n",
            "Epoch 49: val_accuracy did not improve from 0.68382\n",
            "53/53 - 70s - loss: 0.3925 - accuracy: 0.8416 - val_loss: 1.0290 - val_accuracy: 0.6483 - 70s/epoch - 1s/step\n",
            "Epoch 50/100\n",
            "\n",
            "Epoch 50: val_loss did not improve from 0.82927\n",
            "\n",
            "Epoch 50: val_accuracy did not improve from 0.68382\n",
            "53/53 - 70s - loss: 0.4023 - accuracy: 0.8319 - val_loss: 1.0626 - val_accuracy: 0.6140 - 70s/epoch - 1s/step\n",
            "Epoch 51/100\n",
            "\n",
            "Epoch 51: val_loss did not improve from 0.82927\n",
            "\n",
            "Epoch 51: val_accuracy did not improve from 0.68382\n",
            "53/53 - 70s - loss: 0.3895 - accuracy: 0.8403 - val_loss: 1.0009 - val_accuracy: 0.6789 - 70s/epoch - 1s/step\n",
            "Epoch 52/100\n",
            "\n",
            "Epoch 52: val_loss did not improve from 0.82927\n",
            "\n",
            "Epoch 52: val_accuracy did not improve from 0.68382\n",
            "53/53 - 77s - loss: 0.3841 - accuracy: 0.8373 - val_loss: 1.0114 - val_accuracy: 0.6446 - 77s/epoch - 1s/step\n",
            "Epoch 53/100\n",
            "\n",
            "Epoch 53: val_loss did not improve from 0.82927\n",
            "\n",
            "Epoch 53: val_accuracy improved from 0.68382 to 0.68995, saving model to VGG19_model_accuracy.h5\n",
            "53/53 - 69s - loss: 0.3981 - accuracy: 0.8346 - val_loss: 1.0333 - val_accuracy: 0.6900 - 69s/epoch - 1s/step\n",
            "Epoch 54/100\n",
            "\n",
            "Epoch 54: val_loss did not improve from 0.82927\n",
            "\n",
            "Epoch 54: val_accuracy did not improve from 0.68995\n",
            "53/53 - 69s - loss: 0.4087 - accuracy: 0.8286 - val_loss: 1.2238 - val_accuracy: 0.6446 - 69s/epoch - 1s/step\n",
            "Epoch 55/100\n",
            "\n",
            "Epoch 55: val_loss did not improve from 0.82927\n",
            "\n",
            "Epoch 55: val_accuracy did not improve from 0.68995\n",
            "53/53 - 70s - loss: 0.3953 - accuracy: 0.8365 - val_loss: 0.9826 - val_accuracy: 0.6422 - 70s/epoch - 1s/step\n",
            "Epoch 56/100\n",
            "\n",
            "Epoch 56: val_loss did not improve from 0.82927\n",
            "\n",
            "Epoch 56: val_accuracy did not improve from 0.68995\n",
            "53/53 - 69s - loss: 0.3930 - accuracy: 0.8316 - val_loss: 1.1336 - val_accuracy: 0.6814 - 69s/epoch - 1s/step\n",
            "Epoch 57/100\n",
            "\n",
            "Epoch 57: val_loss did not improve from 0.82927\n",
            "\n",
            "Epoch 57: val_accuracy did not improve from 0.68995\n",
            "53/53 - 69s - loss: 0.3878 - accuracy: 0.8324 - val_loss: 0.9413 - val_accuracy: 0.6679 - 69s/epoch - 1s/step\n",
            "Epoch 58/100\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('VGG19._model.h5')"
      ],
      "metadata": {
        "id": "mkHfJfFUXIwU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}